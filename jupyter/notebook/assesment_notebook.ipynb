{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyspark in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: py4j in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Installing PySpark in Jupyter Notebook and other environments.\n",
    "\n",
    "%pip install findspark\n",
    "%pip install pyspark\n",
    "%pip install py4j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import all dependencies ### for the Spark job\n",
    "# Importing necessary libraries\n",
    "\n",
    "import findspark\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import socket\n",
    "import time\n",
    "import psutil\n",
    "import logging\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import random\n",
    "import string\n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'findspark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfindspark\u001b[49m.init()\n",
      "\u001b[31mNameError\u001b[39m: name 'findspark' is not defined"
     ]
    }
   ],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set up logging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mlogging\u001b[49m.basicConfig(level=logging.INFO)\n\u001b[32m      4\u001b[39m spark = SparkSession.builder. \\\n\u001b[32m      5\u001b[39m     appName(\u001b[33m\"\u001b[39m\u001b[33mdata_engineering_task\u001b[39m\u001b[33m\"\u001b[39m). \\\n\u001b[32m      6\u001b[39m     getOrCreate()\n",
      "\u001b[31mNameError\u001b[39m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "    appName(\"data_engineering_task\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job ID: integer (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: integer (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: double (nullable = true)\n",
      " |-- Salary Range To: double (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: string (nullable = true)\n",
      " |-- Post Until: string (nullable = true)\n",
      " |-- Posting Updated: string (nullable = true)\n",
      " |-- Process Date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 06:13:56 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_file = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load(\"/workspaces/data_engineering_task/dataset/nyc-jobs.csv\")\n",
    "\n",
    "data_file.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 06:14:14 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------+--------------+--------------------+--------------------+-------------+-----+--------------------+-----------------------------+-----------------+---------------+----------------+--------------------+--------------------+--------------------+-------------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Job ID|              Agency|Posting Type|# Of Positions|      Business Title| Civil Service Title|Title Code No|Level|        Job Category|Full-Time/Part-Time indicator|Salary Range From|Salary Range To|Salary Frequency|       Work Location|  Division/Work Unit|     Job Description|Minimum Qual Requirements|    Preferred Skills|Additional Information|            To Apply|         Hours/Shift|     Work Location 1| Recruitment Contact|Residency Requirement|        Posting Date|          Post Until|     Posting Updated|        Process Date|\n",
      "+------+--------------------+------------+--------------+--------------------+--------------------+-------------+-----+--------------------+-----------------------------+-----------------+---------------+----------------+--------------------+--------------------+--------------------+-------------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 87990|DEPARTMENT OF BUS...|    Internal|             1|     Account Manager|CONTRACT REVIEWER...|        40563|    1|                NULL|                         NULL|          42405.0|        65485.0|          Annual| 110 William St. N Y|Strategy & Analytics|Division of Econo...|     \"1.\\tA baccalaure...| all candidates m...|  â€¢\\tExcellent in...|Salary range for ...|                NULL|                NULL|                NULL|                 NULL|New York City res...|2011-06-24T00:00:...|                NULL|2011-06-24T00:00:...|\n",
      "| 97899|DEPARTMENT OF BUS...|    Internal|             1|EXECUTIVE DIRECTO...|ADMINISTRATIVE BU...|        10009|   M3|                NULL|                            F|          60740.0|       162014.0|          Annual| 110 William St. N Y|Tech Talent Pipeline|The New York City...|     \"1. A baccalaurea...|                NULL|                  NULL|In addition to ap...|                NULL|                NULL|                NULL| New York City res...|2012-01-26T00:00:...|                NULL|2012-01-26T00:00:...|2019-12-17T00:00:...|\n",
      "|132292|NYC HOUSING AUTHO...|    External|            52|Maintenance Worke...|  MAINTENANCE WORKER|        90698|    0|Maintenance & Ope...|                            F|         51907.68|       54580.32|          Annual|Heating Mgt-Opera...|Management Servic...|Under direct supe...|     \"1. Three years o...|          mechanical|   or construction ...| may be substitut...| all candidates m...|1.  A High School...|1.  A Motor Vehic...| \"Click the \"\"Appl...|                NULL|                NULL|                NULL|NYCHA has no resi...|\n",
      "|132292|NYC HOUSING AUTHO...|    Internal|            52|Maintenance Worke...|  MAINTENANCE WORKER|        90698|    0|Maintenance & Ope...|                            F|         51907.68|       54580.32|          Annual|Heating Mgt-Opera...|Management Servic...|Under direct supe...|     \"1. Three years o...|          mechanical|   or construction ...| may be substitut...| all candidates m...|1.  A High School...|1.  A Motor Vehic...| \"Click the \"\"Appl...|                NULL|                NULL|                NULL|NYCHA has no resi...|\n",
      "|133921|NYC HOUSING AUTHO...|    Internal|            50|   Temporary Painter|             PAINTER|        91830|    0|Maintenance & Ope...|                            F|             35.0|           35.0|          Hourly|DMP-Contract & An...|Dept of Managemen...|Responsibilities ...|     1. Five years of ...|                NULL|  SPECIAL NOTE:    ...|\"Click the \"\"Appl...|                NULL|                NULL|                NULL| NYCHA has no resi...|2014-01-09T00:00:...|                NULL|2014-01-08T00:00:...|2019-12-17T00:00:...|\n",
      "+------+--------------------+------------+--------------+--------------------+--------------------+-------------+-----+--------------------+-----------------------------+-----------------+---------------+----------------+--------------------+--------------------+--------------------+-------------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.show(5)\n",
    "data_file.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_frequency(df: DataFrame) -> list:\n",
    "    row_list = df.select('Salary Frequency').distinct().collect()\n",
    "    return [row['Salary Frequency'] for row in row_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('A', 'Annual'), ('B', 'Daily')]\n",
    "expected_result = ['Annual', 'Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_salary_frequency(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['id', 'Salary Frequency']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    assert get_salary_frequency(mock_df) == expected_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
