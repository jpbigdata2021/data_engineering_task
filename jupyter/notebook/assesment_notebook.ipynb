{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing PySpark in Jupyter Notebook and other environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "Requirement already satisfied: findspark in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "INFO:py4j.clientserver:Closing down clientserver connection\n",
      "INFO:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "INFO:py4j.clientserver:Closing down clientserver connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "Requirement already satisfied: pyspark in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "IOStream.flush timed out\n",
      "Requirement already satisfied: py4j in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%pip install findspark\n",
    "%pip install pyspark\n",
    "%pip install py4j\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all dependencies for the Spark job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "\n",
    "import findspark\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, avg, count, max, min, collect_list\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql.functions import col\n",
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder. \\\n",
    "    appName(\"data_engineering_task\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reading data and printing schema values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "INFO:py4j.clientserver:Closing down clientserver connection\n",
      "INFO:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "INFO:py4j.clientserver:Closing down clientserver connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count before remove duplicate 2946\n",
      "count after removed duplicate 2946\n",
      "root\n",
      " |-- Job ID: integer (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: integer (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: double (nullable = true)\n",
      " |-- Salary Range To: double (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: string (nullable = true)\n",
      " |-- Post Until: string (nullable = true)\n",
      " |-- Posting Updated: string (nullable = true)\n",
      " |-- Process Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_file = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load(\"/workspaces/data_engineering_task/dataset/nyc-jobs.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Remove duplicate rows\n",
    "print(\"count before remove duplicate\",data_file.count())\n",
    "#data_file = data_file.dropDuplicates()\n",
    "# Print the schema to understand column types\n",
    "print(\"count after removed duplicate\",data_file.count())\n",
    "# Print the schema to understand column types\n",
    "data_file.printSchema()\n",
    "# Show the first few rows of the DataFrame\n",
    "#data_file.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+\n",
      "|summary|    # Of Positions| Salary Range From|  Salary Range To|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "|  count|              2946|              2946|             2946|\n",
      "|   mean|2.4959266802443993| 58904.13979385609|85535.71162739306|\n",
      "| stddev| 9.281312826466838|26986.575935791363|42871.31345366745|\n",
      "|    min|                 1|               0.0|            10.36|\n",
      "|    max|               200|          218587.0|         234402.0|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "\n",
      "Distinct values in Agency:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|Agency                        |\n",
      "+------------------------------+\n",
      "|OFFICE OF COLLECTIVE BARGAININ|\n",
      "|FIRE DEPARTMENT               |\n",
      "|ADMIN FOR CHILDREN'S SVCS     |\n",
      "|MANHATTAN COMMUNITY BOARD #8  |\n",
      "|TAXI & LIMOUSINE COMMISSION   |\n",
      "|DEPARTMENT OF BUSINESS SERV.  |\n",
      "|DEPT OF DESIGN & CONSTRUCTION |\n",
      "|FINANCIAL INFO SVCS AGENCY    |\n",
      "|DEPARTMENT OF CORRECTION      |\n",
      "|HOUSING PRESERVATION & DVLPMNT|\n",
      "+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Distinct values in Posting Type:\n",
      "+------------+\n",
      "|Posting Type|\n",
      "+------------+\n",
      "|Internal    |\n",
      "|External    |\n",
      "+------------+\n",
      "\n",
      "Distinct values in Title Code No:\n",
      "+-------------+\n",
      "|Title Code No|\n",
      "+-------------+\n",
      "|70822        |\n",
      "|52408        |\n",
      "|51193        |\n",
      "|22508        |\n",
      "|34615        |\n",
      "|91001        |\n",
      "|52040        |\n",
      "|12158        |\n",
      "|51011        |\n",
      "|20415        |\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Distinct values in Level:\n",
      "+-----+\n",
      "|Level|\n",
      "+-----+\n",
      "|3    |\n",
      "|M4   |\n",
      "|M7   |\n",
      "|4B   |\n",
      "|0    |\n",
      "|M6   |\n",
      "|M1   |\n",
      "|4A   |\n",
      "|M5   |\n",
      "|M2   |\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Distinct values in Job Category:\n",
      "+-----------------------------------------------------------------------------------+\n",
      "|Job Category                                                                       |\n",
      "+-----------------------------------------------------------------------------------+\n",
      "|Information Technology & Telecommunications Policy & Analysis Social Services      |\n",
      "|Legal Affairs Policy, Research & Analysis Public Safety, Inspections, & Enforcement|\n",
      "|Constituent Services & Community Programs                                          |\n",
      "|Building Operations & Maintenance                                                  |\n",
      "|Legal Affairs                                                                      |\n",
      "|Health Legal Affairs                                                               |\n",
      "|Administration & Human Resources Social Services                                   |\n",
      "|Maintenance & Operations                                                           |\n",
      "|Public Safety, Inspections, & Enforcement Social Services                          |\n",
      "|Clerical & Administrative Support Legal                                            |\n",
      "+-----------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Distinct values in Full-Time/Part-Time indicator:\n",
      "+-----------------------------+\n",
      "|Full-Time/Part-Time indicator|\n",
      "+-----------------------------+\n",
      "|F                            |\n",
      "|P                            |\n",
      "|NULL                         |\n",
      "+-----------------------------+\n",
      "\n",
      "Distinct values in Salary Frequency:\n",
      "+----------------+\n",
      "|Salary Frequency|\n",
      "+----------------+\n",
      "|Annual          |\n",
      "|Daily           |\n",
      "|Hourly          |\n",
      "+----------------+\n",
      "\n",
      "+------+------+------------+--------------+--------------+-------------------+-------------+-----+------------+-----------------------------+-----------------+---------------+----------------+-------------+------------------+---------------+-------------------------+----------------+----------------------+--------+-----------+---------------+-------------------+---------------------+------------+----------+---------------+------------+\n",
      "|Job ID|Agency|Posting Type|# Of Positions|Business Title|Civil Service Title|Title Code No|Level|Job Category|Full-Time/Part-Time indicator|Salary Range From|Salary Range To|Salary Frequency|Work Location|Division/Work Unit|Job Description|Minimum Qual Requirements|Preferred Skills|Additional Information|To Apply|Hours/Shift|Work Location 1|Recruitment Contact|Residency Requirement|Posting Date|Post Until|Posting Updated|Process Date|\n",
      "+------+------+------------+--------------+--------------+-------------------+-------------+-----+------------+-----------------------------+-----------------+---------------+----------------+-------------+------------------+---------------+-------------------------+----------------+----------------------+--------+-----------+---------------+-------------------+---------------------+------------+----------+---------------+------------+\n",
      "|     0|     0|           0|             0|             0|                  0|            0|    0|           2|                          195|                0|              0|               0|            0|                 0|              0|                       18|             259|                   563|     180|       1062|           1138|               1763|                  678|         517|      1499|            508|         425|\n",
      "+------+------+------------+--------------+--------------+-------------------+-------------+-----+------------+-----------------------------+-----------------+---------------+----------------+-------------+------------------+---------------+-------------------------+----------------+----------------------+--------+-----------+---------------+-------------------+---------------------+------------+----------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summary statistics for numerical columns\n",
    "data_file.describe([\"# Of Positions\", \"Salary Range From\", \"Salary Range To\"]).show()\n",
    "\n",
    "# Count distinct values for categorical columns\n",
    "categorical_columns = [\"Agency\", \"Posting Type\", \"Title Code No\", \"Level\", \"Job Category\", \"Full-Time/Part-Time indicator\", \"Salary Frequency\"]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    print(f\"Distinct values in {column}:\")\n",
    "    data_file.select(column).distinct().show(10, truncate=False)\n",
    "\n",
    "\n",
    "# Count null values in each column\n",
    "data_file.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in data_file.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#List of KPIs to be resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|Agency                        |count|\n",
      "+------------------------------+-----+\n",
      "|DEPT OF ENVIRONMENT PROTECTION|655  |\n",
      "|NYC HOUSING AUTHORITY         |231  |\n",
      "|DEPT OF HEALTH/MENTAL HYGIENE |188  |\n",
      "|DEPARTMENT OF TRANSPORTATION  |183  |\n",
      "|DEPT OF DESIGN & CONSTRUCTION |142  |\n",
      "|TAXI & LIMOUSINE COMMISSION   |134  |\n",
      "|ADMIN FOR CHILDREN'S SVCS     |108  |\n",
      "|DEPT OF INFO TECH & TELECOMM  |107  |\n",
      "|LAW DEPARTMENT                |95   |\n",
      "|HOUSING PRESERVATION & DVLPMNT|86   |\n",
      "+------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Count the number of jobs per agency\n",
    "agency_counts = data_file.groupBy(\"Agency\").count().orderBy(\"count\", ascending=False)\n",
    "agency_counts.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|Job Category                             |count|\n",
      "+-----------------------------------------+-----+\n",
      "|Engineering, Architecture, & Planning    |504  |\n",
      "|Technology, Data & Innovation            |313  |\n",
      "|Legal Affairs                            |226  |\n",
      "|Public Safety, Inspections, & Enforcement|182  |\n",
      "|Building Operations & Maintenance        |181  |\n",
      "|Finance, Accounting, & Procurement       |169  |\n",
      "|Administration & Human Resources         |134  |\n",
      "|Constituent Services & Community Programs|129  |\n",
      "|Health                                   |125  |\n",
      "|Policy, Research & Analysis              |124  |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.number of jobs posting per category top 10:\n",
    "job_category_counts = data_file.filter(col(\"Job Category\").isNotNull()).groupBy(\"Job Category\").count().orderBy(\"count\", ascending=False)\n",
    "job_category_counts.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----------------------+---------------------+---------------+\n",
      "|Job Category                             |Total Salary Range From|Total Salary Range To|Total Positions|\n",
      "+-----------------------------------------+-----------------------+---------------------+---------------+\n",
      "|Engineering, Architecture, & Planning    |3.3320681810000002E7   |5.188658181E7        |762            |\n",
      "|Technology, Data & Innovation            |2.1777043960500002E7   |3.33524432098E7      |405            |\n",
      "|Legal Affairs                            |1.58365392558E7        |2.17911463106E7      |515            |\n",
      "|Finance, Accounting, & Procurement       |1.00772180668E7        |1.48655259762E7      |275            |\n",
      "|Public Safety, Inspections, & Enforcement|9363633.7292           |1.32629547906E7      |1407           |\n",
      "|Policy, Research & Analysis              |6804147.8412           |8963123.9008         |200            |\n",
      "|Constituent Services & Community Programs|6465005.999599999      |8467409.0738         |149            |\n",
      "|Health                                   |6300456.8704           |8316123.837699999    |358            |\n",
      "|Administration & Human Resources         |5847514.3444           |8559054.7862         |330            |\n",
      "|Building Operations & Maintenance        |5464046.238599999      |8146211.598599997    |1249           |\n",
      "+-----------------------------------------+-----------------------+---------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. salary distribution per job category\n",
    "salary_distribution = data_file.groupBy(\"Job Category\").agg(sum(\"Salary Range From\").alias(\"Total Salary Range From\"),\n",
    "                                                            sum(\"Salary Range To\").alias(\"Total Salary Range To\"),\n",
    "                                                            sum(\"# Of Positions\").alias(\"Total Positions\")) \\\n",
    "    .orderBy(\"Total Salary Range From\", ascending=False)\n",
    "salary_distribution.show(10, truncate=False)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Degree Type  |\n",
      "+-------------+\n",
      "|baccalaureate|\n",
      "|baccalaureate|\n",
      "|             |\n",
      "|             |\n",
      "|             |\n",
      "|             |\n",
      "|baccalaureate|\n",
      "|baccalaureate|\n",
      "|s            |\n",
      "|             |\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.Correlation between the higher degree and the salary.\n",
    "\n",
    "data_with_degree = data_file.withColumn(\n",
    "    \"Degree Type\",\n",
    "    regexp_extract(col(\"Minimum Qual Requirements\"), r\"(\\w+)\\sdegree\", 1)\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "data_with_degree.select(\"Degree Type\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------------------+--------------------+\n",
      "|Agency                        |max(Salary Range From)|max(Salary Range To)|\n",
      "+------------------------------+----------------------+--------------------+\n",
      "|NYC EMPLOYEES RETIREMENT SYS  |130000.0              |234402.0            |\n",
      "|POLICE DEPARTMENT             |200000.0              |234402.0            |\n",
      "|NYC HOUSING AUTHORITY         |175000.0              |234402.0            |\n",
      "|DEPT OF HEALTH/MENTAL HYGIENE |157725.0              |225217.0            |\n",
      "|DEPT OF ENVIRONMENT PROTECTION|218587.0              |218587.0            |\n",
      "|DEPT OF DESIGN & CONSTRUCTION |86346.0               |217244.0            |\n",
      "|DISTRICT ATTORNEY KINGS COUNTY|175000.0              |208826.0            |\n",
      "|DEPARTMENT OF SANITATION      |87490.0               |202744.0            |\n",
      "|DEPT OF INFO TECH & TELECOMM  |96020.0               |189000.0            |\n",
      "|DEPARTMENT OF PROBATION       |79620.0               |180000.0            |\n",
      "+------------------------------+----------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Job posting having the highest salary per agency\n",
    "highest_salary_per_agency = data_file.groupBy(\"Agency\").agg(\n",
    "    {\"Salary Range From\": \"max\", \"Salary Range To\": \"max\"}\n",
    ").orderBy(\"max(Salary Range To)\", ascending=False)\n",
    "highest_salary_per_agency.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----------------------+----------------------+--------------------+\n",
      "|Agency                        |Posting Date           |avg(Salary Range From)|avg(Salary Range To)|\n",
      "+------------------------------+-----------------------+----------------------+--------------------+\n",
      "|NYC HOUSING AUTHORITY         |2019-05-14T00:00:00.000|103620.0              |234402.0            |\n",
      "|POLICE DEPARTMENT             |2019-10-30T00:00:00.000|200000.0              |234402.0            |\n",
      "|DEPT OF ENVIRONMENT PROTECTION|2019-05-28T00:00:00.000|218587.0              |218587.0            |\n",
      "|DEPT OF DESIGN & CONSTRUCTION |2019-10-11T00:00:00.000|86346.0               |217244.0            |\n",
      "|NYC HOUSING AUTHORITY         |2019-01-29T00:00:00.000|78574.0               |202744.0            |\n",
      "|DEPT OF ENVIRONMENT PROTECTION|2017-03-02T00:00:00.000|75338.0               |194395.0            |\n",
      "|DEPT OF ENVIRONMENT PROTECTION|2017-04-06T00:00:00.000|75338.0               |194395.0            |\n",
      "|DEPT OF ENVIRONMENT PROTECTION|2017-04-20T00:00:00.000|175000.0              |190000.0            |\n",
      "|NYC HOUSING AUTHORITY         |2019-10-09T00:00:00.000|86346.0               |187000.0            |\n",
      "|DEPT OF ENVIRONMENT PROTECTION|2019-01-15T00:00:00.000|69940.0               |186555.0            |\n",
      "+------------------------------+-----------------------+----------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Job positings average salary per agency for the last 2 years\n",
    "\n",
    "#finding most lasted year to find last 2 years data.\n",
    " \n",
    "find_year = data_file.withColumn(\"Year\", year(col(\"Posting Date\"))).distinct()\n",
    "current_year=find_year.filter(col(\"year\").isNotNull()).select(\"Year\").orderBy(\"Year\",ascending=False).first()[\"Year\"]\n",
    "\n",
    "\n",
    "# Filter data for the last 2 years\n",
    "filtered_data = data_file.filter(\n",
    "    (col(\"Posting Date\").isNotNull()) & \n",
    "    (year(col(\"Posting Date\")) >= (current_year - 2))\n",
    ")\n",
    "\n",
    "# Calculate average salary per agency\n",
    "average_salary_per_agency = filtered_data.filter(col(\"Posting Date\").isNotNull()) \\\n",
    "    .groupBy(\"Agency\",\"Posting Date\") \\\n",
    "    .agg({\"Salary Range From\": \"avg\", \"Salary Range To\": \"avg\"}) \\\n",
    "    .orderBy(\"avg(Salary Range To)\", ascending=False)\n",
    "average_salary_per_agency.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+-------------------+\n",
      "|Skill       |Avg Salary Range From|Avg Salary Range To|\n",
      "+------------+---------------------+-------------------+\n",
      "|making      |200000.0             |234402.0           |\n",
      "|responsible |82680.0              |188559.25          |\n",
      "|research    |69940.0              |180000.0           |\n",
      "|consultative|130000.0             |137410.0           |\n",
      "|recent      |69940.0              |133327.0           |\n",
      "|auditing    |95834.0              |130865.75          |\n",
      "|fulltime    |70274.18181818182    |126326.0           |\n",
      "|related     |84767.66666666667    |119502.44444444444 |\n",
      "|technology  |86932.53125          |119117.5625        |\n",
      "|specialized |87909.45454545454    |117739.18181818182 |\n",
      "+------------+---------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7 highest paid skills in the US market\n",
    "\n",
    "def find_highest_paid_skills(df: DataFrame) -> DataFrame:\n",
    "    # Extract skills or keywords from the \"Job Description\" or \"Minimum Qual Requirements\" column\n",
    "    df_with_skills = df.withColumn(\n",
    "        \"Skill\",\n",
    "        regexp_extract(col(\"Minimum Qual Requirements\"), r\"(\\w+)\\s(skill|experience|knowledge)\", 1)\n",
    "    )\n",
    "    \n",
    "    # Filter rows where skills are identified\n",
    "    df_with_skills = df_with_skills.filter(col(\"Skill\").isNotNull())\n",
    "    \n",
    "    # Calculate the average salary for each skill\n",
    "    skill_salary = df_with_skills.groupBy(\"Skill\").agg(\n",
    "        avg(\"Salary Range From\").alias(\"Avg Salary Range From\"),\n",
    "        avg(\"Salary Range To\").alias(\"Avg Salary Range To\")\n",
    "    ).orderBy(\"Avg Salary Range To\", ascending=False)\n",
    "    \n",
    "    return skill_salary\n",
    "\n",
    "# Example usage\n",
    "highest_paid_skills = find_highest_paid_skills(data_file)\n",
    "highest_paid_skills.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count before removing duplicates: 2946\n",
      "Count after removing duplicates: 2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/16 17:05:35 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/04/16 17:05:35 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/04/16 17:05:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/04/16 17:05:36 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore codespace@127.0.0.1\n",
      "25/04/16 17:05:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "25/04/16 17:05:38 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/04/16 17:05:38 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/04/16 17:05:38 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/04/16 17:05:38 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    def clean_dataset(df: DataFrame) -> DataFrame:\n",
    "        print(f\"Count before removing duplicates: {df.count()}\")\n",
    "        df = df.dropDuplicates()\n",
    "        print(f\"Count after removing duplicates: {df.count()}\")\n",
    "        return df\n",
    "\n",
    "    # Function to preprocess columns (e.g., extract year, clean text)\n",
    "    def preprocess_columns(df: DataFrame) -> DataFrame:\n",
    "        df = df.withColumn(\"Year\", year(col(\"Posting Date\")))\n",
    "        df = df.withColumn(\n",
    "            \"Degree Type\",\n",
    "            regexp_extract(col(\"Minimum Qual Requirements\"), r\"(\\w+)\\sdegree\", 1)\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    # Function for data wrangling (e.g., filtering, grouping)\n",
    "    def wrangle_data(df: DataFrame, current_year: int) -> DataFrame:\n",
    "        # Filter data for the last 2 years\n",
    "        filtered_data = df.filter(\n",
    "            (col(\"Posting Date\").isNotNull()) & \n",
    "            (year(col(\"Posting Date\")) >= (current_year - 2))\n",
    "        )\n",
    "        return filtered_data\n",
    "\n",
    "    # Function for data transformation (e.g., aggregations, calculations)\n",
    "    def transform_data(df: DataFrame) -> DataFrame:\n",
    "        # Example: Calculate average salary per agency\n",
    "        transformed_df = df.groupBy(\"Agency\").agg(\n",
    "            sum(\"Salary Range From\").alias(\"Total Salary Range From\"),\n",
    "            sum(\"Salary Range To\").alias(\"Total Salary Range To\"),\n",
    "            sum(\"# Of Positions\").alias(\"Total Positions\")\n",
    "        ).orderBy(\"Total Salary Range From\", ascending=False)\n",
    "        return transformed_df\n",
    "\n",
    "    # Clean the dataset\n",
    "    data_file = clean_dataset(data_file)\n",
    "\n",
    "    # Preprocess columns\n",
    "    data_file = preprocess_columns(data_file)\n",
    "\n",
    "    # Find the current year\n",
    "    current_year = data_file.select(year(col(\"Posting Date\")).alias(\"Year\")).distinct().orderBy(col(\"Year\").desc()).first()[\"Year\"]\n",
    "\n",
    "    # Wrangle the data\n",
    "    filtered_data = wrangle_data(data_file, current_year)\n",
    "\n",
    "    # Transform the data\n",
    "    final_data = transform_data(filtered_data)\n",
    "\n",
    "    # Final transformed data to save as file.\n",
    "    final_data.write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\").save(\"/workspaces/data_engineering_task/dataset/final_transformed_data.csv\")\n",
    "\n",
    "    # final data to write to hive table (make sure final table exists).\n",
    "    spark.sql(\"CREATE DATABASE IF NOT EXISTS sample_db\")\n",
    "    final_data.write.format(\"orc\").mode(\"overwrite\").saveAsTable(\"sample_db.final_transformed_data\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Stop the Spark session\n",
    "    spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
